# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: gaze_combined
  - override /model: gazenet
  - override /callbacks: default
  - override /trainer: gpu
  - override /logger: wandb
  - override /extras: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

seed: 12345

trainer:
  min_epochs: 5
  max_epochs: 9
  gradient_clip_val: 1
  #accumulate_grad_batches: 3
  # precision: 16 # speed up training by using 16-bit precision
  # # debug 
  # max_epochs: 7
  # overfit_batches: 3
  # limit_test_batches: 10

callbacks:
  model_checkpoint:
    monitor: "val/angular_all"
    mode: "min"
  
  early_stopping: 
    monitor: "val/angular_all"
    patience: 5
    mode: "min"

model:
  solver:
    lr: 0.00001
    weight_decay: 0.001
    layer_decay: null
    warmup_epochs: 5
    scheduler: "steplr"
    decay_steps: [3,6]
    decay_gamma: 0.5
    apply_linear_scaling: True
  
  net:
    _target_: gaze_module.models.components.gaze_models.GazeNet
    encoder: ${extras.swin_v2_t} # resnet18, resnet50, swin_v2_t, inception_v3
    head:
      _target_: gaze_module.models.components.gaze_models.HeadCartesian
      _partial_: true
    activation:
      _target_: torch.nn.ReLU
  
  loss:
    #_target_: gaze_module.models.losses.CosineGazeLoss
    _target_: gaze_module.models.losses.AngularArcossLoss

  mode_angular: cartesian
  pretrained_path : /idiap/temp/pvuillecard/projects/gaze_pretrain/logs/experiments/generalize/run_2024-06-30_14-28-18/logs/train/runs/run_0/checkpoints/best_epoch_028.ckpt

data:

  datasets_train:
    # - ${extras.gaze360}
    # - ${extras.gazefollow_pseudo}
    # - ${extras.mpsgaze}
    # - ${extras.gfie}
  
  train_transform:
    _target_: gaze_module.data.components.transforms.Compose
    transforms:
      - _target_: gaze_module.data.components.transforms.BboxReshape
        square: True
        ratio: ${extras.bbox_scale_ratio}
      - _target_: gaze_module.data.components.transforms.ToImage
      - _target_: gaze_module.data.components.transforms.CropRandomResize
        output_size: ${model.net.encoder.head_size}
        scale: [0.9,1]
        ratio: [0.9,1.1]
      - _target_: gaze_module.data.components.transforms.HorizontalFlip
      - _target_: gaze_module.data.components.transforms.ColorJitter
        brightness: [0.5, 1.5]
        contrast: [0.5, 1.5]
        saturation: [0.2, 1.5]
        hue: null
        p: 0.5
      - _target_: gaze_module.data.components.transforms.RandomGaussianBlur
        radius: 5
        p: 0.5
      - _target_: gaze_module.data.components.transforms.ToTensor
      - _target_: gaze_module.data.components.transforms.Normalize
        mean: [0.485, 0.456, 0.406]
        std: [0.229, 0.224, 0.225]
  
  batch_size: 120 # Needs to be divisible by the number of devices (e.g., if in a distributed setup)
  num_workers: 10
  # batch_size: 120 # Needs to be divisible by the number of devices (e.g., if in a distributed setup)
  # num_workers: 10
  data_to_cluster: False

tags: ["finetuning", "gaze360",swin_v2_t]

logger:
  wandb:
    tags: ${tags}
    group: "finetuning"
  aim:
    experiment: "finetuning model trained on everything"

